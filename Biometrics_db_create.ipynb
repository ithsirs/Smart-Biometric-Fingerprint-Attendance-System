{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sZpxsOEGlWh",
        "outputId": "29bf1576-6745-4de6-ebbf-c5442e205c78"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import psycopg2\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from psycopg2.extras import execute_values\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from pgvector.psycopg2 import register_vector\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import psycopg2\n",
        "\n",
        "\n",
        "def connect():\n",
        "    conn = psycopg2.connect('REDACTED')# Create you own database and set the connection string here\n",
        "\n",
        "    query_sql = 'SELECT VERSION()'\n",
        "\n",
        "    cur = conn.cursor()\n",
        "    return cur, conn\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FDyhAkM9MEOp"
      },
      "outputs": [],
      "source": [
        "path = 'D:\\\\Biometric attendance\\\\SOCOFing\\\\Real'\n",
        "MODEL_PATH = 'D:\\\\Biometric attendance\\\\fingerprint_model.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# -----------------------------------------\n",
        "# 1) Recreate your metric-learning model\n",
        "# -----------------------------------------\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "class FingerprintNet(nn.Module):\n",
        "    def __init__(self, embedding_dim=128):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        num_ftrs = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Linear(num_ftrs, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.normalize(self.backbone(x), p=2, dim=1)\n",
        "\n",
        "# -----------------------------------------\n",
        "# 2) Load your fine-tuned model\n",
        "# -----------------------------------------\n",
        "MODEL_PATH = \"D:\\\\Biometric attendance\\\\fingerprint_model.pth\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = FingerprintNet(embedding_dim=128).to(device)\n",
        "state = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
        "model.load_state_dict(state)\n",
        "model.eval()\n",
        "\n",
        "# -----------------------------------------\n",
        "# 3) Precompute gallery embeddings\n",
        "# -----------------------------------------\n",
        "DATA_DIR = path\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# gather all BMP paths\n",
        "gallery_paths = []\n",
        "for root, _, files in os.walk(DATA_DIR):\n",
        "    for f in files:\n",
        "        if f.lower().endswith(\".bmp\"):\n",
        "            gallery_paths.append(os.path.join(root, f))\n",
        "gallery_paths.sort()\n",
        "\n",
        "# compute embeddings\n",
        "gallery_records = []  # list of (file_id, [128 floats])\n",
        "with torch.no_grad():\n",
        "    for path in gallery_paths:\n",
        "        img = Image.open(path).convert(\"L\")\n",
        "        t   = transform(img).unsqueeze(0).to(device)\n",
        "        emb = model(t).cpu().numpy().flatten().tolist()\n",
        "        file_id = os.path.basename(path)\n",
        "        gallery_records.append((file_id, emb))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "cur, conn = connect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tgYi9eWF9VC"
      },
      "outputs": [],
      "source": [
        "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Rkj6ShfFdge"
      },
      "outputs": [],
      "source": [
        "cur.execute(\"\"\"CREATE TABLE users (\n",
        "    user_id INT PRIMARY KEY,\n",
        "    gender VARCHAR(10) CHECK (gender IN ('M', 'F')),\n",
        "    dept VARCHAR(50),\n",
        "    year INT CHECK (year >= 1 AND year <= 5)\n",
        ");\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EXOpcMYwiZt"
      },
      "outputs": [],
      "source": [
        "conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbBLmpeDGIFM"
      },
      "outputs": [],
      "source": [
        "cur.execute(\"\"\"\n",
        "    CREATE TABLE fingerprint_metadata (\n",
        "        file_id VARCHAR(255) PRIMARY KEY,  -- e.g., 133__M_Right_index_finger.BMP\n",
        "        user_id INT REFERENCES users(user_id),\n",
        "        gender VARCHAR(10) CHECK (gender IN ('M', 'F')),\n",
        "        hand_side VARCHAR(10) CHECK (hand_side IN ('Left', 'Right')),\n",
        "        finger VARCHAR(20)  -- e.g., 'index', 'thumb', etc.\n",
        "    );\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkfJlROhGQpA"
      },
      "outputs": [],
      "source": [
        "cur.execute(\n",
        "    \"\"\"CREATE TABLE attendance (\n",
        "    attendance_id SERIAL PRIMARY KEY,\n",
        "    user_id INT REFERENCES users(user_id),\n",
        "    date DATE NOT NULL DEFAULT CURRENT_DATE,\n",
        "    status VARCHAR(10) NOT NULL CHECK (status IN ('present', 'absent'))\n",
        ");\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "cur.execute(\n",
        "    \"\"\"CREATE TABLE mark_attendance(\n",
        "    attendance_id VARCHAR(512) PRIMARY KEY,\n",
        "    user_id INT REFERENCES users(user_id),\n",
        "    department VARCHAR(128) NOT NULL,\n",
        "    year INT NOT NULL CHECK (year >= 1 AND year <= 5),\n",
        "    subject_code VARCHAR(128) NOT NULL,\n",
        "    date DATE NOT NULL DEFAULT CURRENT_DATE,\n",
        "    status VARCHAR(10) NOT NULL CHECK (status IN ('present', 'absent'))\n",
        "    )\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "cur.execute(\n",
        "    \"\"\"CREATE TABLE department(\n",
        "    department VARCHAR(128),\n",
        "    year INT NOT NULL CHECK (year >= 1 AND year <= 5),\n",
        "    semester INT NOT NULL,\n",
        "    subject_code VARCHAR(128) PRIMARY KEY,\n",
        "    subject_name VARCHAR(255) NOT NULL\n",
        "    )\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upserted 6000 embeddings into the database\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------\n",
        "# 4) Upsert into Postgres\n",
        "# -----------------------------------------\n",
        "cur, conn = connect()\n",
        "register_vector(conn)  # enables pgvector support\n",
        "\n",
        "\n",
        "# create table if not exists\n",
        "cur.execute(\"\"\"\n",
        "CREATE EXTENSION IF NOT EXISTS vector;\n",
        "CREATE TABLE IF NOT EXISTS public.fingerprint_embeddings_new (\n",
        "  file_id TEXT PRIMARY KEY,\n",
        "  embedding VECTOR(128)\n",
        ");\n",
        "\"\"\")\n",
        "\n",
        "cur.execute(\n",
        "    \"\"\"CREATE INDEX fingerprint_embedding_new_hnsw_idx\n",
        "ON fingerprint_embeddings_new\n",
        "USING hnsw (embedding vector_l2_ops);\n",
        "\"\"\")\n",
        "\n",
        "# upsert all records in one batch\n",
        "execute_values(cur,\n",
        "    \"\"\"\n",
        "    INSERT INTO public.fingerprint_embeddings_new (file_id, embedding)\n",
        "    VALUES %s\n",
        "    ON CONFLICT (file_id) DO UPDATE\n",
        "      SET embedding = EXCLUDED.embedding\n",
        "    \"\"\",\n",
        "    gallery_records,\n",
        "    template=\"(%s, %s::vector)\"  # tell psycopg2 that 2nd field is vector\n",
        ")\n",
        "\n",
        "conn.commit()\n",
        "cur.close()\n",
        "conn.close()\n",
        "print(f\"Upserted {len(gallery_records)} embeddings into the database\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ISbK0rwPXjUw"
      },
      "outputs": [],
      "source": [
        "conn.commit()\n",
        "cur.close()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1KqBtOHfml0",
        "outputId": "e26927a4-e942-4192-b6b0-e52927be05eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in fingerprint_embeddings table: 6000\n"
          ]
        }
      ],
      "source": [
        "# prompt: count the number of rows in fingerprint_embeddings table\n",
        "\n",
        "cur.execute(\"SELECT COUNT(*) FROM fingerprint_embeddings;\")\n",
        "row_count = cur.fetchone()[0]\n",
        "print(f\"Number of rows in fingerprint_embeddings table: {row_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvCwGCVIHTI8"
      },
      "outputs": [],
      "source": [
        "# === Mock department & year ===\n",
        "departments = ['CSE', 'ECE', 'IT', 'ME','CE','CHE']\n",
        "years = ['1', '2', '3', '4', '5']\n",
        "user_inserted = set()\n",
        "\n",
        "# === Load dataset ===\n",
        "real_path = '/kaggle/input/socofing/SOCOFing/Real'\n",
        "MODEL_PATH = '/content/fingerprint_model.pth'\n",
        "\n",
        "\n",
        "# === Process each image ===\n",
        "for filename in os.listdir(real_path):\n",
        "    if not filename.endswith(\".BMP\"):\n",
        "        continue\n",
        "\n",
        "    file_id = filename  # e.g. 133__M_Right_index_finger.BMP\n",
        "    user_id = int(file_id.split(\"__\")[0])\n",
        "    gender = file_id.split(\"__\")[1].split(\"_\")[0]\n",
        "    hand = file_id.split(\"__\")[1].split(\"_\")[1]\n",
        "    finger = file_id.split(\"__\")[1].split(\"_\")[2].replace(\".BMP\", \"\")\n",
        "\n",
        "    # Extract image embedding\n",
        "    img_path = os.path.join(real_path, filename)\n",
        "    img = Image.open(img_path).convert(\"L\")\n",
        "    img_tensor = transform(img).unsqueeze(0).cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        embedding = model(img_tensor).cpu().numpy().flatten()\n",
        "\n",
        "    embedding_str = \"[\" + \", \".join(map(str, embedding)) + \"]\"\n",
        "\n",
        "\n",
        "        # === Insert user with mock data (Table 3) ===\n",
        "    if user_id not in user_inserted:\n",
        "        dept = random.choice(departments)\n",
        "        year = random.choice(years)\n",
        "        cur.execute(\"\"\"\n",
        "            INSERT INTO users (user_id, gender, dept, year)\n",
        "            VALUES (%s, %s, %s, %s)\n",
        "            ON CONFLICT (user_id) DO NOTHING;\n",
        "        \"\"\", (user_id,gender, dept, year))\n",
        "        user_inserted.add(user_id)\n",
        "\n",
        "    # === Insert metadata (Table 1) ===\n",
        "    cur.execute(\"\"\"\n",
        "        INSERT INTO fingerprint_metadata (file_id, user_id, gender, hand_side, finger)\n",
        "        VALUES (%s, %s, %s, %s, %s)\n",
        "        ON CONFLICT (file_id) DO NOTHING;\n",
        "    \"\"\", (file_id, user_id, gender, hand, finger))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the original CSV\n",
        "df = pd.read_csv(\"subject_codes_with_names.csv\")\n",
        "\n",
        "# Drop the unwanted columns\n",
        "df_cleaned = df.drop(columns=[\"Code\"])\n",
        "\n",
        "# Save the cleaned version\n",
        "df_cleaned.to_csv(\"subject_codes_cleaned.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "cur, conn = connect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 180 rows processed from CSV.\n",
            "✅ Data inserted successfully and connection closed.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "# Connect to PostgreSQL\n",
        "try:\n",
        "    \n",
        "    # Load data from CSV and insert\n",
        "    with open(\"subject_codes_cleaned.csv\", mode='r', encoding='utf-8') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        inserted = 0\n",
        "        for row in reader:\n",
        "            cur.execute(\"\"\"\n",
        "                INSERT INTO department (department, year,semester, subject_code, subject_name)\n",
        "                VALUES (%s, %s, %s,%s, %s)\n",
        "                ON CONFLICT (subject_code) DO NOTHING;\n",
        "            \"\"\", (\n",
        "                row['Department'], row['Year'], row['Semester'],row['Subject_Code'], row['Subject_Name']\n",
        "            ))\n",
        "            inserted += 1\n",
        "        print(f\"{inserted} rows processed from CSV.\")\n",
        "\n",
        "    # Commit changes and close\n",
        "    conn.commit()\n",
        "    cur.close()\n",
        "    conn.close()\n",
        "    print(\"Data inserted successfully and connection closed.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\" Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7ARnfEUPXAE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
