{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6YdCjgsQ9Gx"
   },
   "source": [
    "# Adding new Real World fingerprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7887,
     "status": "ok",
     "timestamp": 1747083553819,
     "user": {
      "displayName": "B Chat",
      "userId": "07241606252220286037"
     },
     "user_tz": -330
    },
    "id": "MYRsZyNPcA28",
    "outputId": "33d0f982-a3a4-4fc4-f4cb-f1f4f028dff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pgvector\n",
      "  Downloading pgvector-0.4.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pgvector) (2.0.2)\n",
      "Downloading pgvector-0.4.1-py3-none-any.whl (27 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary, pgvector\n",
      "Successfully installed pgvector-0.4.1 psycopg2-binary-2.9.10\n"
     ]
    }
   ],
   "source": [
    "!pip install pgvector psycopg2-binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4121,
     "status": "ok",
     "timestamp": 1747083572775,
     "user": {
      "displayName": "B Chat",
      "userId": "07241606252220286037"
     },
     "user_tz": -330
    },
    "id": "5sWoz2nVkNOi",
    "outputId": "a81e30d3-28ba-4e1e-d1ac-578cf8c81996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/socofing/SOCOFing/Real/\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ruizgara/socofing\")\n",
    "path = path + \"/SOCOFing/Real/\"\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sb2xrQAGs96w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OiJdxTBD1pHI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8fABVcLG3jq"
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "\n",
    "def connect():\n",
    "    conn = psycopg2.connect('Enter your own database credentials here')\n",
    "\n",
    "    query_sql = 'SELECT VERSION()'\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    return cur, conn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zu2ZCM8VS_tx"
   },
   "source": [
    "# Addition of new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1747083997857,
     "user": {
      "displayName": "B Chat",
      "userId": "07241606252220286037"
     },
     "user_tz": -330
    },
    "id": "b2k7IBg_URUW",
    "outputId": "db04ce5b-1caa-4d75-b6b9-8a99370aac8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 178MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FingerprintNet(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# 1) Recreate your metric-learning model\n",
    "# -----------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "class FingerprintNet(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_ftrs = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(num_ftrs, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.backbone(x), p=2, dim=1)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2) Load your fine-tuned model\n",
    "# -----------------------------------------\n",
    "MODEL_PATH = \"/content/fingerprint_model_finetuned2.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FingerprintNet(embedding_dim=128).to(device)\n",
    "state = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.load_state_dict(state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4581,
     "status": "ok",
     "timestamp": 1747084485769,
     "user": {
      "displayName": "B Chat",
      "userId": "07241606252220286037"
     },
     "user_tz": -330
    },
    "id": "UQuZEruSS_NC",
    "outputId": "fa910a5d-cb70-4cc6-e7ff-2040e0a72ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new fingerprint files to add.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "# ────── 1. Assumed globals ──────\n",
    "# (from earlier code)\n",
    "DB_CONFIG: dict             # your Postgres connection dict\n",
    "file_ids: list              # current in-memory list of file_id strings\n",
    "embeddings: np.ndarray      # current in-memory array shape [N,128]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# ────── 2. Function to fetch existing IDs from DB ──────\n",
    "def fetch_existing_file_ids():\n",
    "    cur, conn = connect()\n",
    "    register_vector(conn)\n",
    "    cur.execute(\"SELECT file_id FROM public.fingerprint_embedding3;\")\n",
    "    rows = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return {row[0] for row in rows}\n",
    "\n",
    "# ────── 3. Add new fingerprints ──────\n",
    "def add_new_fingerprints(new_dir: str):\n",
    "    # 3a) find all BMPs under new_dir\n",
    "    new_paths = []\n",
    "    for root, _, files in os.walk(new_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".bmp\"):\n",
    "                new_paths.append(os.path.join(root, f))\n",
    "    new_paths.sort()\n",
    "\n",
    "    # 3b) skip paths already in DB\n",
    "    existing_ids = fetch_existing_file_ids()\n",
    "    to_add = [p for p in new_paths if os.path.basename(p) not in existing_ids]\n",
    "    if not to_add:\n",
    "        print(\"No new fingerprint files to add.\")\n",
    "        return\n",
    "    else:\n",
    "      print(f\"Adding {len(to_add)} new fingerprint files.\")\n",
    "\n",
    "    # 3c) compute embeddings\n",
    "    records = []\n",
    "    with torch.no_grad():\n",
    "        for path in to_add:\n",
    "            img = Image.open(path).convert(\"L\")\n",
    "            t   = transform(img).unsqueeze(0).to(device)  # [1,1,224,224]\n",
    "            emb = model(t).cpu().numpy().flatten().tolist()\n",
    "            fid = os.path.basename(path)\n",
    "            records.append((fid, emb))\n",
    "\n",
    "    # 3d) upsert into DB\n",
    "    cur, conn = connect()\n",
    "    register_vector(conn)\n",
    "    execute_values(cur,\n",
    "        \"\"\"\n",
    "        INSERT INTO public.fingerprint_embedding3 (file_id, embedding)\n",
    "        VALUES %s\n",
    "        ON CONFLICT (file_id) DO UPDATE\n",
    "          SET embedding = EXCLUDED.embedding\n",
    "        \"\"\",\n",
    "        records,\n",
    "        template=\"(%s, %s::vector)\"\n",
    "    )\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(f\"Upserted {len(records)} new embeddings into DB.\")\n",
    "\n",
    "    # 3e) update in-memory lists\n",
    "    global file_ids, embeddings\n",
    "    for fid, emb in records:\n",
    "        file_ids.append(fid)\n",
    "        embeddings = np.vstack([embeddings, np.array(emb, dtype=float)])\n",
    "\n",
    "# ────── 4. Usage ──────\n",
    "# Point this at your “new fingerprints” folder:\n",
    "add_new_fingerprints(\"/content/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5025,
     "status": "ok",
     "timestamp": 1747084467754,
     "user": {
      "displayName": "B Chat",
      "userId": "07241606252220286037"
     },
     "user_tz": -330
    },
    "id": "tvqwcLIidzoZ",
    "outputId": "a8236b04-d015-473c-fd1b-87b63a6298da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6001 embeddings from DB\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# 5) Fetch all embeddings at once\n",
    "# -----------------------------------------\n",
    "def load_all_embeddings():\n",
    "    cur, conn = connect()\n",
    "    register_vector(conn)\n",
    "    cur.execute(\"SELECT file_id, embedding FROM public.fingerprint_embedding3 ORDER BY file_id ASC;\")\n",
    "    rows = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    file_ids = [row[0] for row in rows]\n",
    "    embeddings = np.stack([np.array(row[1], dtype=float) for row in rows], axis=0)\n",
    "    return file_ids, embeddings\n",
    "\n",
    "# Usage:\n",
    "file_ids, embeddings = load_all_embeddings()\n",
    "print(\"Loaded\", len(file_ids), \"embeddings from DB\")\n",
    "gallery_embeddings = np.array(embeddings)  # shape [N,128]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqShq4oFS_Jn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M80rLRFVlIM3"
   },
   "source": [
    "# Embedding and Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41512,
     "status": "ok",
     "timestamp": 1747004930147,
     "user": {
      "displayName": "B Chat",
      "userId": "07241606252220286037"
     },
     "user_tz": -330
    },
    "id": "nLix-2znbH5Y",
    "outputId": "88e2191e-efdd-461c-8977-bc7feb4aa17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted 6000 embeddings into the database\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1) Recreate your metric-learning model\n",
    "# -----------------------------------------\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "class FingerprintNet(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_ftrs = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(num_ftrs, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.backbone(x), p=2, dim=1)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2) Load your fine-tuned model\n",
    "# -----------------------------------------\n",
    "MODEL_PATH = \"/content/fingerprint_model_finetuned2.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FingerprintNet(embedding_dim=128).to(device)\n",
    "state = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3) Precompute gallery embeddings\n",
    "# -----------------------------------------\n",
    "DATA_DIR = path\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# gather all BMP paths\n",
    "gallery_paths = []\n",
    "for root, _, files in os.walk(DATA_DIR):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(\".bmp\"):\n",
    "            gallery_paths.append(os.path.join(root, f))\n",
    "gallery_paths.sort()\n",
    "\n",
    "# compute embeddings\n",
    "gallery_records = []  # list of (file_id, [128 floats])\n",
    "with torch.no_grad():\n",
    "    for path in gallery_paths:\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        t   = transform(img).unsqueeze(0).to(device)\n",
    "        emb = model(t).cpu().numpy().flatten().tolist()\n",
    "        file_id = os.path.basename(path)\n",
    "        gallery_records.append((file_id, emb))\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4) Upsert into Postgres\n",
    "# -----------------------------------------\n",
    "cur, conn = connect()\n",
    "register_vector(conn)  # enables pgvector support\n",
    "\n",
    "\n",
    "# create table if not exists\n",
    "cur.execute(\"\"\"\n",
    "CREATE EXTENSION IF NOT EXISTS vector;\n",
    "CREATE TABLE IF NOT EXISTS public.fingerprint_embedding3 (\n",
    "  file_id TEXT PRIMARY KEY,\n",
    "  embedding VECTOR(128)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# upsert all records in one batch\n",
    "execute_values(cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO public.fingerprint_embedding3 (file_id, embedding)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (file_id) DO UPDATE\n",
    "      SET embedding = EXCLUDED.embedding\n",
    "    \"\"\",\n",
    "    gallery_records,\n",
    "    template=\"(%s, %s::vector)\"  # tell psycopg2 that 2nd field is vector\n",
    ")\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(f\"Upserted {len(gallery_records)} embeddings into the database\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFXR-Vq61izX"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_zG5vKkdzk7"
   },
   "outputs": [],
   "source": [
    "def predict_fingerprint_from_db(test_image_path, top_k=1):\n",
    "    img = Image.open(test_image_path).convert(\"L\")\n",
    "    t = transform(img).unsqueeze(0)  # shape [1,1,224,224]\n",
    "    t = t.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        q_emb = model(t).cpu().numpy()  # shape [1,128]\n",
    "\n",
    "    sims = cosine_similarity(q_emb, gallery_embeddings)[0]  # shape [N]\n",
    "    best_idxs = np.argsort(sims)[::-1][:top_k]\n",
    "\n",
    "    results = [(file_ids[i], float(sims[i])) for i in best_idxs]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVzO43DwkqMs"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747084868410,
     "user": {
      "displayName": "B Chat",
      "userId": "07241606252220286037"
     },
     "user_tz": -330
    },
    "id": "6QxFM5CPbH19",
    "outputId": "583e482b-2bee-4f25-d176-66fdbeb76acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matches:\n",
      "→ 515__M_Right_thumb_finger.BMP (similarity: 0.9734)\n",
      "→ 136__F_Left_little_finger.BMP (similarity: 0.9698)\n",
      "→ 92__F_Right_thumb_finger.BMP (similarity: 0.9560)\n"
     ]
    }
   ],
   "source": [
    "query_img = \"/content/test.bmp\"\n",
    "matches = predict_fingerprint_from_db(query_img, top_k=3)\n",
    "\n",
    "print(\"Top matches:\")\n",
    "for file_id, score in matches:\n",
    "    print(f\"→ {file_id} (similarity: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIEaS1-6nLke"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1ehWGKPPGzwEdI1Spxr7T_qdZBwLev8lm",
     "timestamp": 1747083492548
    },
    {
     "file_id": "1L7U5YyDrUjILkYRZVPiaiT7ujLlhMH0b",
     "timestamp": 1747001688610
    },
    {
     "file_id": "1dhHJshQzO18964u2lNaMcEX4RtmHabUZ",
     "timestamp": 1746787141558
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
